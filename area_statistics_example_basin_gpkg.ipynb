{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47149d1d-6286-4cb0-97e0-9c1165182cd6",
   "metadata": {},
   "source": [
    "# Drainage basin area average\n",
    "\n",
    "In this notebook we calculate the fractional area average of Australian drainage basins for all ensemble members.\n",
    "\n",
    "The outcome is to calculate the ensemble median of the mean hazard value for each basin.\n",
    "\n",
    "Data is to be sorted by the hazard value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36cc4a65-2673-412c-8759-0d5ecd7d3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to correct working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a14c8e-f291-474a-86d3-39637c7f2728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/g/data/mn51/users/gt3409/plotting_maps\n"
     ]
    }
   ],
   "source": [
    "cd /g/data/mn51/users/gt3409/plotting_maps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848da856-4643-4764-9ce9-05b6a8548ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed packages\n",
    "from acs_area_statistics import acs_regional_stats, regions\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "import cartopy.crs as ccrs\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50334a2f-d9e5-4f5b-991c-c75fa0df7ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67df14f3-0110-474b-802c-e512343de559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the individual models for GWL30-GWL12 anomalies only\n",
    "var = \"TXx\"\n",
    "\n",
    "filelist = glob(f\"/g/data/ia39/ncra/heat/data/{var}/bias-corrected/individual_models/GWL-change/\\\n",
    "{var}_AGCD-05i_*_ssp370*_v1-r1-ACS-QME-AGCD-1960-2022_GWL30-GWL12-change.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f34021-cccd-4889-bd02-6df5b54d203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.01/lib/python3.10/site-packages/geopandas/io/file.py:399: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  as_dt = pd.to_datetime(df[k], errors=\"ignore\")\n",
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-24.01/lib/python3.10/site-packages/geopandas/io/file.py:399: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  as_dt = pd.to_datetime(df[k], errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "# read in the data for the areas to average across\n",
    "gdf = gpd.read_file(\"/g/data/mn51/users/ah7841/NCBLevel2DrainageBasinGroup_gda2020_v01.gpkg\")\n",
    "\n",
    "#convert geometry to lat lon (from northings)\n",
    "gdf.geometry = gdf.geometry.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# There are duplicated of IDs. Merge geometries with the same IDs\n",
    "gdf = gdf.dissolve(by=\"HydroID\").reset_index()\n",
    "\n",
    "# use the geopandas dataframe to make a regionmask object\n",
    "regions = regionmask.from_geopandas(gdf, \n",
    "                                    names= \"Level2Name\",\n",
    "                                    abbrevs= \"HydroID\",\n",
    "                                    name=\"NCBLevel2DrainageBasinGroup_gda2020_v01\", \n",
    "                                    overlap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974715bc-7e93-435a-9da8-b523b35624cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your mask\n",
    "# You can also use a keyword for the function to calculate the mask, but if you're performing multiple calculations, this can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b3284-ba6e-4e35-a08a-b7e6edeec318",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# make sure you request more than 24GB memory\n",
    "# calculate weighted mask this is a very slow part of the code and\n",
    "# can be reused for any datasets using the same regions and the same lat lon\n",
    "ds = xr.open_dataset(filelist[0], use_cftime = True,)\n",
    "mask_frac = regions.mask_3D_frac_approx(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40eda1a-d811-4a1f-9b82-efc01b8f7a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate the area averages for each drainage basin\n",
    "\n",
    "dict_means = {}\n",
    "for file in filelist:\n",
    "    ensemble_member = \"-\".join([file.split(\"/\")[-1].split(\"_\")[i] for i in (5,6,2,4)])\n",
    "    ds =  xr.open_dataset(file, use_cftime = True,)\n",
    "    ds = ds.expand_dims(dim= {\"ensemble_member\":[ensemble_member]}, axis=0)\n",
    "    df = acs_regional_stats(ds=ds,\n",
    "                                var=var, \n",
    "                                mask=mask_frac, \n",
    "                                dims = (\"lat\", \"lon\",), \n",
    "                                how = [\"mean\"])\n",
    "    # Round to two decimal places (eg for temperature anomalies)\n",
    "    df[f\"{var}_mean\"] = df[f\"{var}_mean\"].round(2)\n",
    "\n",
    "    dict_means.update({ensemble_member:df})\n",
    "# merge each ensemble member into one xarray dataset\n",
    "ds_means = xr.merge([dict_means[key] for key in dict_means.keys()])\n",
    "\n",
    "# calculate the ensemble median per region\n",
    "ens_median = ds_means.median(dim=\"ensemble_member\").expand_dims(dim= {\"ensemble_member\":[\"ensemble_median\"]}, axis=0)\n",
    "# then add it to the xr dataset\n",
    "ds_means = xr.merge([ds_means, ens_median])\n",
    "\n",
    "# present the data as a simple table\n",
    "df_means = xr.merge([ds_means, ens_median]).to_dataframe()[f\"{var}_mean\"].unstack().T\n",
    "\n",
    "df_means[\"ID\"] = gdf.HydroID\n",
    "df_means[\"name\"] = gdf.Level2Name\n",
    "df_means = df_means[[\"ID\", \"name\"] + list(df_means.keys()[0:-2])]\n",
    "\n",
    "# Rank regions by ensemble median\n",
    "df_means_sorted = df_means.sort_values(by = \"ensemble_median\", ascending=False)\n",
    "df_means_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c4b20-a5e1-4562-8612-ff7396310b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means_sorted.to_csv(f\"/g/data/mn51/users/gt3409/plotting_maps/{var}_NCBLevel2DrainageBasinGroup-gda2020-v01_MME_ssp370_v1-r1-ACS-QME-AGCD-1960-2022_GWL30-GWL12-change.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0e84c-921f-4fd7-9027-2195f92ba4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
